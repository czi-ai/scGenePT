{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8B3Qjzdw23t"
   },
   "source": [
    "# scGenePT Perturbation Prediction Tutorial \n",
    "\n",
    "<a id = 'introduction'></a>\n",
    "Last Updated: [11/14/2024] This notebook offers examples of how to use trained scGenePT models in inference mode for perturbation prediction. It uses models fine-tuned on the **Norman [1] dataset** and offers examples of predicting post-perturbation expression responses for **single gene perturbations**: POU3F2, CDKN1B and **gene combinations**: SAMD1+ZBTB1. Models have not been evaluated on multiple gene combination perturbation responses, so behavior is unknown. \n",
    "\n",
    "**Model** : scGenePT is a collection of single-cell models for perturbation prediction. It leverages the [scGPT](https://github.com/bowang-lab/scGPT) [2] foundation model for scRNAseq data by injecting language embeddings at the gene level into the model architecture. The language gene embeddings are obtained by embedding gene level information from different knowledge sources using LLMs. The knowledge sources used include NCBI gene descriptions, UniProt protein Summaries for protein coding genes - as inspired by the [genePT](https://github.com/yiqunchen/GenePT) [3] approach - and GO (Gene Ontology) Gene Molecular Annotations, across three different axes: Molecular Function, Biological Process and Cellular Component. The model variations available are:\n",
    "- **scGenePT_NCBI** = scGPT + NCBI Gene Card Summaries\n",
    "- **scGenePT_NCBI+UniProt** = scGPT + NCBI Gene Card Summaries + UniProt Protein Summaries\n",
    "- **scGenePT_GO−F** = scGPT + GO Molecular Functions Annotations\n",
    "- **scGenePT_GO−C** = scGPT + GO Cellular Components Annotations\n",
    "- **scGenePT_GO−P** = scGPT + GO Biological Processes Annotations\n",
    "- **scGenePT+GO−all** = scGPT + GO_F + GO_C + GO_P\n",
    "\n",
    "**Dataset**: The Norman Dataset [1] is a CRISPR perturb-seq dataset containing single and two-gene perturbations. We use a processed version of the dataset that contains 105 single and 131 two-gene combinations perturbations coming from 91k observations. Cells in the dataset are log-normalized and filtered to the top 5000 highly variable genes. Models in ths notebook are trained on the train split of the dataset. We offer examples of:\n",
    "- performing inference on the test split of the Norman dataset\n",
    "- performing inference on a random control sample and on a new anndata file\n",
    "\n",
    "**The notebook is structured and offers the following examples**:\n",
    "1. [Perturbation prediction](#perturbation_prediction)\n",
    "    - [Load the Norman dataset](#load_dataset)\n",
    "    - [Load a trained scGenePT model](#load_trained_scgenept_model)\n",
    "2. [Plotting the top 20 Differentially Expressed Genes post-perturbation](#plot_top_20_de)\n",
    "    - [Predicting perturbation response for perturbing the POU3F2 gene using a scGenePT_GO−C model](#example_POU3F2+ctrl)\n",
    "    - [Predicting perturbation response for perturbing the CDKN1B gene using a scGenePT_GO−C model](#example_CDKN1B+ctrl)\n",
    "    - [Predicting perturbation response for perturbing the SAMD1+ZBTB1 gene combination using a scGenePT_NCBI+UniProt model](#example_SAMD1+ZBTB1) \n",
    "3. [Perturbation prediction on NumPy arrays holding control samples](#prediction_on_rnd_ctrl)\n",
    "4. [Perturbation prediction on AnnData files](#prediction_on_new_anndata_file)\n",
    "\n",
    "<!-- **The full list of resources available is**:\n",
    "1. [bioRxiv Preprint](https://www.biorxiv.org/content/10.1101/2024.10.23.619972v1)\n",
    "2. [scGenePT Trained Model Weights](https://drive.google.com/drive/u/0/folders/12h1hL3cJF3W0VG92JqGJ1-4R-2nDXbzc)\n",
    "3. [Gene Embeddings, computed using LLMs](https://drive.google.com/drive/folders/191d8uXaoUNvvZ8DZHzlR1O6BK9vLnqqy?usp=drive_link) <br>\n",
    "• NCBI Gene Card summaries, NCBI Gene Card Summaries + UniProt Protein Summaries <br>\n",
    "• GO-C Cellular Components Gene Annotations, GO-F Molecular Function Gene Annotations, GO-P Biological Process Gene Annotations, GO-all (GO-C + GO-F + GO-P) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEFliUdPxthd"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hardware Requirements** <br>\n",
    "We strongly recommend running this notebook on a GPU instance. It should run on a CPU as well, but it will be much slower.\n",
    "\n",
    "**Prerequisites**\n",
    "1. The notebook must run inside a virtual env containing the needed packages. If you already created one, then you can skip this step. If you haven't, you must create one. First, you'll need to clone the repo through: <br>\n",
    "\n",
    "```\n",
    "git clone git@github.com:czi-ai/scGenePT.git\n",
    "```\n",
    "\n",
    "\n",
    "Then you need to create a virtual environment containing the model packaging dependencies. The `requirements.txt` file is under the repo.\n",
    "\n",
    "```python\n",
    "conda create -y --name scgenept python=3.10\n",
    "source activate scgenept\n",
    "pip install -r requirements.txt\n",
    "pip install flash-attn --no-build-isolation\n",
    "pip install scgpt \"flash-attn<1.0.5\"\n",
    "```\n",
    "\n",
    "2. Once you have a venv created, activate it and allow the jupyter notebook to use it as a kernel by running the following command from the terminal. If jupyter is not installed, it should be:\n",
    "```python\n",
    "pip install ipykernel\n",
    "pip install jupyter\n",
    "python -m ipykernel install --user --name=scgenept\n",
    "```\n",
    "\n",
    "3. Open the jupyter notebook. You should now be able to see and select a new kernel: scgenept. The notebook needs to be ran inside this kernel in order for all packages to be properly installed.\n",
    "\n",
    "**Model and Data**\n",
    "\n",
    "These steps are also described under the [GitHub README](https://github.com/czi-ai/scGenePT/blob/main/README.md): \n",
    "- **Download Gene Embeddings** - the gene embeddings files should be under `models/gene_embeddings` - you only need to download the gene embeddings of the models you are interested in. In this tutorial, we will focus on **scGenePT_GO−C** and **scGenePT_NCBI+UniProt**, so you need to download:\n",
    "    - GO_C_gene_embeddings-gpt3.5-ada-concat.pickle | [Download Link](https://drive.google.com/file/d/1oGnxs56GqGQA5gaocg4uPf_UwtomJ0Tp/view?usp=drive_link)\n",
    "    - NCBI+UniProt_embeddings-gpt3.5-ada.pkl | [Download Link](https://drive.google.com/file/d/1EyuQwY8B3DU3W2VBuiBSoJiJw7KHntu4/view?usp=drive_link)\n",
    "- **Download Trained scGenePT models from the scGenePT Model Zoo** - they should be under `models/finetuned` for the purpose of this tutorial, we need the following models:\n",
    "    - scgpt/norman/best_model_seed_42.pt | [Download Link](https://drive.google.com/file/d/1OzTVmj24k_QrLAwKkwv8Q6SNW4yDcW00/view?usp=drive_link) \n",
    "    - scgenept_go_c/norman/best_model_gpt3.5_ada_rnd_seed_42_concat.pt | [Download Link](https://drive.google.com/file/d/17tsBhTkuEw1uwTSvsK9Hskq3px_3MIQU/view?usp=drive_link)\n",
    "    - scgenept_ncbi+uniprot/best_model_gpt3.5_ada_rnd_seed_42.pt | [Download Link](https://drive.google.com/file/d/1w7lGESKGzYRzuHSOaUwJj0ALyiFADxYi/view?usp=drive_link) <br>\n",
    "Note that you can download all finetuned models from [this link](https://drive.google.com/drive/folders/1U9PodoV7A-Dkk-GemmLB_AzmkgE-owp_?usp=drive_link).\n",
    "- **(Optional) Download Gene Annotations** - this can help visualize some of the gene annotations that got embedded; they should be under `models/gene_embeddings/gene_annotations`:\n",
    "     - gene_ontology_C.csv | [Download Link](https://drive.google.com/file/d/1KDi5WnTh1AGOvg1GO868WudVQJeo64Xi/view?usp=drive_link)\n",
    "     - gene_ontology_P.csv | [Download Link](https://drive.google.com/file/d/1sDjQSxLRYDyyt1CCGdVS-FuL9mp6OhdX/view?usp=drive_link)\n",
    "     - gene_ontology_F.csv | [Download Link](https://drive.google.com/file/d/19QquVKvvFD3yzlJGjbYtIspgTeSr41V1/view?usp=drive_link)\n",
    "     - NCBI_summary_of_genes.json | [Download Link](https://drive.google.com/file/d/118lo79pIhOs5lhIv6aNuoaNhnGnjquNC/view?usp=drive_link)\n",
    "     - NCBI_UniProt_summary_of_genes.json | [Download Link](https://drive.google.com/file/d/1kiENkEdR74BPhNo9Zxu2iwBi2kSJDWtH/view?usp=drive_link)\n",
    "\n",
    "**Your folder structure should now look something like**:\n",
    "\n",
    "```\n",
    "- models\n",
    "    - pretrained\n",
    "        - scgpt/vocab.json\n",
    "    - gene_embeddings\n",
    "        - GO_C_gene_embeddings-gpt3.5-ada-concat.pickle\n",
    "        - NCBI+UniProt_embeddings-gpt3.5-ada.pkl\n",
    "        - gene_annotations\n",
    "            - gene_ontology_C.csv\n",
    "            - gene_ontology_P.csv\n",
    "            - gene_ontology_F.csv\n",
    "            - NCBI_summary_of_genes.json\n",
    "            - NCBI_UniProt_summary_of_genes.json\n",
    "    - finetuned\n",
    "        - scgenept_go_c/norman/best_model_gpt3.5_ada_rnd_seed_42_concat.pt\n",
    "        - scgenept_ncbi+uniprot/norman/best_model_gpt3.5_ada_rnd_seed_42_concat.pt\n",
    "- tutorials\n",
    "    - scgenept_tutorial.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aNSqZsf2xwlg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/einops/_torch_specific.py:109: ImportWarning: allow_ops_in_compiled_graph failed to import torch: ensure pytorch >=2.0\n",
      "  warnings.warn(\"allow_ops_in_compiled_graph failed to import torch: ensure pytorch >=2.0\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from train import load_dataloader\n",
    "from utils.data_loading import *\n",
    "from models.scGenePT import *\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from gears.inference import evaluate, compute_metrics, deeper_analysis, non_dropout_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMtC5qMd44Mu"
   },
   "source": [
    "<a id='perturbation prediction'></a>\n",
    "## 1. Perturbation Prediction using a trained scGenePT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_dataset'></a>\n",
    "### Load dataset\n",
    "We start by loading the Norman dataset. The dataloaders use a pre-processed version of Norman from [GEARS](https://github.com/snap-stanford/GEARS) [3]. Models in this notebook have been finetuned on the train split of this dataset. We also showcase how to perform inference on the test split of this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Local copy of pyg dataset is detected. Loading...\n",
      "Done!\n",
      "Local copy of split is detected. Loading...\n",
      "Simulation split test composition:\n",
      "combo_seen0:9\n",
      "combo_seen1:52\n",
      "combo_seen2:18\n",
      "unseen_single:37\n",
      "Done!\n",
      "Creating dataloaders....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Has been tested with 'norman' and 'adamson'\n",
    "dataset_name = 'norman' \n",
    "batch_size = 64\n",
    "eval_batch_size = 64\n",
    "\n",
    "pert_data = load_dataloader(dataset_name, batch_size, eval_batch_size, split = 'simulation')\n",
    "train_loader = pert_data.dataloader['train_loader']\n",
    "val_loader = pert_data.dataloader['val_loader']\n",
    "test_loader = pert_data.dataloader['test_loader']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset_exploration'></a>\n",
    "### Dataset Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the data inside the dataloaders. The `pert_data.adata` is an AnnData object containing gene expression counts and additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 91205 × 5045\n",
       "    obs: 'condition', 'cell_type', 'dose_val', 'control', 'condition_name'\n",
       "    var: 'gene_name'\n",
       "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert_data.adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gene expression counts are stored in `pert_adata.adata.X`, where each entry (i, j) entry corresponds to the gene expression counts of gene j in row i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       "\twith 37317477 stored elements and shape (91205, 5045)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert_data.adata.X # 902105 cells, 5045 genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pert_data.adata.obs` file contains information about the different perturbation conditions applied to the data stored in .X. For instance, below we can see examples of 1-gene perturbations: *TSC22D1+ctrl, MAML2+ctrl*, etc, examples of 2-gene perturbations: *KLF1+MAP2K6, CEBPE+RUNX1T1*, and examples of control samples. Each of the conditions corresponds to gene expression counts stored in .X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>dose_val</th>\n",
       "      <th>control</th>\n",
       "      <th>condition_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_barcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGGCATGTG-1</th>\n",
       "      <td>TSC22D1+ctrl</td>\n",
       "      <td>A549</td>\n",
       "      <td>1+1</td>\n",
       "      <td>0</td>\n",
       "      <td>A549_TSC22D1+ctrl_1+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGGCCCTTG-1</th>\n",
       "      <td>KLF1+MAP2K6</td>\n",
       "      <td>A549</td>\n",
       "      <td>1+1</td>\n",
       "      <td>0</td>\n",
       "      <td>A549_KLF1+MAP2K6_1+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGCACGAAGCA-1</th>\n",
       "      <td>ctrl</td>\n",
       "      <td>A549</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A549_ctrl_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGCAGACGTAG-1</th>\n",
       "      <td>CEBPE+RUNX1T1</td>\n",
       "      <td>A549</td>\n",
       "      <td>1+1</td>\n",
       "      <td>0</td>\n",
       "      <td>A549_CEBPE+RUNX1T1_1+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGCAGCCTTGG-1</th>\n",
       "      <td>MAML2+ctrl</td>\n",
       "      <td>A549</td>\n",
       "      <td>1+1</td>\n",
       "      <td>0</td>\n",
       "      <td>A549_MAML2+ctrl_1+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCAGTCATGCAT-8</th>\n",
       "      <td>RHOXF2BB+SET</td>\n",
       "      <td>A549</td>\n",
       "      <td>1+1</td>\n",
       "      <td>0</td>\n",
       "      <td>A549_RHOXF2BB+SET_1+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCAGTACGT-8</th>\n",
       "      <td>FOXA3+ctrl</td>\n",
       "      <td>A549</td>\n",
       "      <td>1+1</td>\n",
       "      <td>0</td>\n",
       "      <td>A549_FOXA3+ctrl_1+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCCACTCCA-8</th>\n",
       "      <td>CELF2+ctrl</td>\n",
       "      <td>A549</td>\n",
       "      <td>1+1</td>\n",
       "      <td>0</td>\n",
       "      <td>A549_CELF2+ctrl_1+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCCCAACGG-8</th>\n",
       "      <td>BCORL1+ctrl</td>\n",
       "      <td>A549</td>\n",
       "      <td>1+1</td>\n",
       "      <td>0</td>\n",
       "      <td>A549_BCORL1+ctrl_1+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCTGGCGAC-8</th>\n",
       "      <td>MAP4K3+ctrl</td>\n",
       "      <td>A549</td>\n",
       "      <td>1+1</td>\n",
       "      <td>0</td>\n",
       "      <td>A549_MAP4K3+ctrl_1+1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91205 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        condition cell_type dose_val  control  \\\n",
       "cell_barcode                                                    \n",
       "AAACCTGAGGCATGTG-1   TSC22D1+ctrl      A549      1+1        0   \n",
       "AAACCTGAGGCCCTTG-1    KLF1+MAP2K6      A549      1+1        0   \n",
       "AAACCTGCACGAAGCA-1           ctrl      A549        1        1   \n",
       "AAACCTGCAGACGTAG-1  CEBPE+RUNX1T1      A549      1+1        0   \n",
       "AAACCTGCAGCCTTGG-1     MAML2+ctrl      A549      1+1        0   \n",
       "...                           ...       ...      ...      ...   \n",
       "TTTGTCAGTCATGCAT-8   RHOXF2BB+SET      A549      1+1        0   \n",
       "TTTGTCATCAGTACGT-8     FOXA3+ctrl      A549      1+1        0   \n",
       "TTTGTCATCCACTCCA-8     CELF2+ctrl      A549      1+1        0   \n",
       "TTTGTCATCCCAACGG-8    BCORL1+ctrl      A549      1+1        0   \n",
       "TTTGTCATCTGGCGAC-8    MAP4K3+ctrl      A549      1+1        0   \n",
       "\n",
       "                            condition_name  \n",
       "cell_barcode                                \n",
       "AAACCTGAGGCATGTG-1   A549_TSC22D1+ctrl_1+1  \n",
       "AAACCTGAGGCCCTTG-1    A549_KLF1+MAP2K6_1+1  \n",
       "AAACCTGCACGAAGCA-1             A549_ctrl_1  \n",
       "AAACCTGCAGACGTAG-1  A549_CEBPE+RUNX1T1_1+1  \n",
       "AAACCTGCAGCCTTGG-1     A549_MAML2+ctrl_1+1  \n",
       "...                                    ...  \n",
       "TTTGTCAGTCATGCAT-8   A549_RHOXF2BB+SET_1+1  \n",
       "TTTGTCATCAGTACGT-8     A549_FOXA3+ctrl_1+1  \n",
       "TTTGTCATCCACTCCA-8     A549_CELF2+ctrl_1+1  \n",
       "TTTGTCATCCCAACGG-8    A549_BCORL1+ctrl_1+1  \n",
       "TTTGTCATCTGGCGAC-8    A549_MAP4K3+ctrl_1+1  \n",
       "\n",
       "[91205 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert_data.adata.obs # perturbation conditions applied to the 902105 cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pert_data.adata.var` gives us the set of genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5045 number of genes present in the dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000239945</th>\n",
       "      <td>RP11-34P13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000223764</th>\n",
       "      <td>RP11-54O7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187634</th>\n",
       "      <td>SAMD11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187642</th>\n",
       "      <td>PERM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000188290</th>\n",
       "      <td>HES4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    gene_name\n",
       "gene_id                      \n",
       "ENSG00000239945  RP11-34P13.8\n",
       "ENSG00000223764   RP11-54O7.3\n",
       "ENSG00000187634        SAMD11\n",
       "ENSG00000187642         PERM1\n",
       "ENSG00000188290          HES4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'There are {len(pert_data.adata.var)} number of genes present in the dataset.')\n",
    "pert_data.adata.var.head() # the names of the 5045 genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load_trained_scgenept'></a>\n",
    "### Load trained scGenePT models\n",
    "\n",
    "In this section, we show examples of loading multiple scGenePT models for prediction in order to compare them. All the models under the scGenePT Model Zoo can be found under [GitHub repo](https://github.com/czi-ai/scGenePT/) and the trained model weights under [this GDrive link](https://drive.google.com/drive/folders/1U9PodoV7A-Dkk-GemmLB_AzmkgE-owp_?usp=drive_link)<br>\n",
    "\n",
    "Here, we load the following:\n",
    "- **scGPT** = scGPT | [Download Link](https://drive.google.com/file/d/17tsBhTkuEw1uwTSvsK9Hskq3px_3MIQU/view?usp=drive_link)\n",
    "- **scGenePT_NCBI+UniProt** = scGPT + NCBI Gene Card Summaries + UniProt Protein Summaries | [Download Link](https://drive.google.com/file/d/17tsBhTkuEw1uwTSvsK9Hskq3px_3MIQU/view?usp=drive_link)\n",
    "- **scGenePT_GO−C** = scGPT + GO Cellular Components Annotations | [Download Link](https://drive.google.com/file/d/17tsBhTkuEw1uwTSvsK9Hskq3px_3MIQU/view?usp=drive_link)\n",
    "\n",
    "Note that models are assumed to be under the `models/finetuned/{dataset_name}/{model_type}/best_model_seed_42.pt` folder\n",
    "\n",
    "\n",
    "**Once the Google Drive files are public, this section should use gdown to automatically download the data under the right folder structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_scgenept_model(pert_data, model_type, models_dir, model_location, device, verbose = False):\n",
    "    embs_to_include = get_embs_to_include(model_type)\n",
    "    vocab_file = models_dir + 'pretrained/scgpt/vocab.json'\n",
    "    vocab, gene_ids, dataset_genes, gene2idx = match_genes_to_scgpt_vocab(vocab_file, pert_data, True, SPECIAL_TOKENS)\n",
    "    ntokens = len(vocab)  # size of vocabulary\n",
    "    genept_embs, genept_emb_type, genept_emb_dim, found_genes_genept = initialize_genept_embeddings(embs_to_include, dataset_genes, vocab, model_type, models_dir)\n",
    "    go_embs_to_include, go_emb_type, go_emb_dim, found_genes_go = initialize_go_embeddings(embs_to_include, dataset_genes, vocab, model_type, models_dir)\n",
    "    \n",
    "    if device == 'cpu':\n",
    "        use_fast_transformer = False\n",
    "    else: \n",
    "        use_fast_transformer = True\n",
    "        \n",
    "    model = scGenePT(\n",
    "        ntoken=ntokens,\n",
    "        d_model=EMBSIZE,\n",
    "        nhead=NHEAD,\n",
    "        d_hid=D_HID,\n",
    "        nlayers=NLAYERS,\n",
    "        nlayers_cls=N_LAYERS_CLS,\n",
    "        n_cls=N_CLS,\n",
    "        vocab=vocab,\n",
    "        n_perturbagens=2,\n",
    "        dropout=0.0,\n",
    "        pad_token=PAD_TOKEN,\n",
    "        pad_value=PAD_VALUE,\n",
    "        pert_pad_id=PERT_PAD_ID,\n",
    "        use_fast_transformer=use_fast_transformer,\n",
    "        embs_to_include = embs_to_include,\n",
    "        genept_embs = genept_embs, \n",
    "        genept_emb_type = genept_emb_type, \n",
    "        genept_emb_size = genept_emb_dim,\n",
    "        go_embs_to_include = go_embs_to_include,\n",
    "        go_emb_type = go_emb_type,\n",
    "        go_emb_size = go_emb_dim\n",
    "    )\n",
    "    \n",
    "    pretrained_params = torch.load(model_location, weights_only=True, map_location = device)\n",
    "    # print(pretrained_params)\n",
    "    if not use_fast_transformer:\n",
    "        pretrained_params = {\n",
    "            k.replace(\"Wqkv.\", \"in_proj_\"): v for k, v in pretrained_params.items()\n",
    "        }\n",
    "    \n",
    "    model.load_state_dict(pretrained_params)\n",
    "    \n",
    "    if verbose:\n",
    "        print(model)\n",
    "    model.to(device)\n",
    "    return model, gene_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "Now loading a scgpt model ... \n",
      "==============================\n",
      "scGenePT model-type: scgpt\n",
      "match 4547/5045 genes in vocabulary of size 60697.\n",
      "Using the following embeddings:['scGPT_counts_embs', 'scGPT_token_embs']\n",
      "Done!\n",
      "\n",
      "Now loading a scgenept_go_c_gpt_concat model ... \n",
      "==============================\n",
      "scGenePT model-type: scgenept_go_c_gpt_concat\n",
      "match 4547/5045 genes in vocabulary of size 60697.\n",
      "Using c GO embs\n",
      "Matched 2945 out of 5045 genes in the GenePT-w embedding\n",
      "Using the following embeddings:['GO_token_embs_gpt_concat', 'scGPT_counts_embs', 'scGPT_token_embs']\n",
      "Done!\n",
      "\n",
      "Now loading a scgenept_ncbi+uniprot_gpt model ... \n",
      "==============================\n",
      "scGenePT model-type: scgenept_ncbi+uniprot_gpt\n",
      "match 4547/5045 genes in vocabulary of size 60697.\n",
      "Using ncbi+uniprot genept embs, embedded with gpt\n",
      "Matched 3351 out of 5045 genes in the GenePT-w embedding\n",
      "Using the following embeddings:['scGPT_counts_embs', 'scGPT_token_embs', 'genePT_token_embs_gpt']\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device {device}')\n",
    "\n",
    "# Mapping from model name to the name of the model file model weights are saved\n",
    "# Note that if you want to experiment with only one or a couple of models only, not all models need to be downloaded\n",
    "model_name2model_variation = {'scgpt' : 'best_model_seed_42.pt',\n",
    "                    'scgenept_ncbi+uniprot_gpt' : 'best_model_gpt3.5_ada_rnd_seed_42.pt',\n",
    "                    'scgenept_go_c_gpt_concat' : 'best_model_gpt3.5_ada_rnd_seed_42_concat.pt'}\n",
    "\n",
    "# To load all the models, uncomment this code and download the specific models from the GDrive link above\n",
    "# model_name2model_variation = {'scgpt' : 'best_model_seed_42.pt', \n",
    "#                     'scgenept_ncbi_gpt' : 'best_model_gpt3.5_ada_rnd_seed_42.pt',\n",
    "#                     'scgenept_ncbi+uniprot_gpt' : 'best_model_gpt3.5_ada_rnd_seed_42.pt',\n",
    "#                     'scgenept_go_c_gpt_concat' : 'best_model_gpt3.5_ada_rnd_seed_42_concat.pt',\n",
    "#                     'scgenept_go_f_gpt_concat' : 'best_model_gpt3.5_ada_rnd_seed_42_concat.pt',\n",
    "#                     'scgenept_go_p_gpt_concat' : 'best_model_gpt3.5_ada_rnd_seed_42_concat.pt',\n",
    "#                     'scgenept_go_all_gpt_concat' : 'best_model_gpt3.5_ada_rnd_seed_42_concat.pt'}\n",
    "\n",
    "# Names of the scGenePT models to load. Note that these have to match the keys in the model_name2model_variation dict\n",
    "models = ['scgpt', 'scgenept_go_c_gpt_concat', 'scgenept_ncbi+uniprot_gpt']\n",
    "# models = ['scgpt',  'scgenept_go_c_gpt_concat', 'scgenept_go_p_gpt_concat', 'scgenept_go_f_gpt_concat', 'scgenept_go_all_gpt_concat', 'scgenept_ncbi_gpt', 'scgenept_ncbi+uniprot_gpt']\n",
    "trained_models = {}\n",
    "\n",
    "# Location of where the pretrained scGPT model and gene embeddings are located\n",
    "pretrained_scgpt_model_dir = '../models/'\n",
    "\n",
    "for model_name in models:\n",
    "    print(f\"Now loading a {model_name} model ... \")\n",
    "    print('=' * 30)\n",
    "    model_filename = model_name2model_variation[model_name]\n",
    "    if model_name != 'scgpt':\n",
    "        model_prefix = ''.join(model_name.split('_gpt')[:-1]) \n",
    "    else:\n",
    "        model_prefix = model_name\n",
    "    model_location =  f'../models/finetuned/{model_prefix}/{dataset_name}/{model_filename}'\n",
    "    model, gene_ids =  load_trained_scgenept_model(pert_data, model_name, pretrained_scgpt_model_dir, model_location, device)\n",
    "    print('Done!\\n')\n",
    "    trained_models[model_name] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSyVsAnf5RaD"
   },
   "source": [
    "<a id='plot_top_20_de'></a>\n",
    "## 2. Plot the Top Differentially Expressed Genes post-perturbation\n",
    "We can use the trained models to perform inference. Below, we offer an example of how to do this on the test split of the Norman dataset - this is novel data the model has not been trained on. The same workflow/analyses can be applied to other data to get similar insights. For instance, in the following sections we offer examples of performing inference  on completely new data, either in numpy or anndata form.\n",
    "\n",
    "We explore the following scenarios and showcase how to plot the top differentially expressed genes post-perturbation for: <br>\n",
    "• **single-gene perturbation**: predicting the effects of perturbing the POU3F2 gene and the CDKN1B gene individually. We offer examples of comparing scGPT with scGenePT_GO−C model predictions <br>\n",
    "• **two-gene perturbation**: predicting the effect of perturbing the SAMD1+ZBTB1 genes simultaneously. We offer an example of comparing scGPT and scGenePT_NCBI+UniProt model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perturbation(\n",
    "    model: nn.Module, query: str, model_type, color, marker, title, save_file: str = None, amp = True, pool_size: int = None\n",
    "):\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    sns.set_theme(style=\"ticks\", rc={\"axes.facecolor\": (0, 0, 0, 0)}, font_scale=1.5)\n",
    "\n",
    "    adata = pert_data.adata\n",
    "    adata_ctrl = adata[adata.obs['condition'] == 'ctrl']\n",
    "    gene_names = pert_data.gene_names.to_list()\n",
    "    \n",
    "    gene2idx = pert_data.node_map\n",
    "    cond2name = dict(adata.obs[[\"condition\", \"condition_name\"]].values)\n",
    "    gene_raw2id = dict(zip(adata.var.index.values, adata.var.gene_name.values))\n",
    "\n",
    "    de_idx = [\n",
    "        gene2idx[gene_raw2id[i]]\n",
    "        for i in adata.uns[\"top_non_zero_de_20\"][cond2name[query]]\n",
    "    ]\n",
    "    genes = [\n",
    "        gene_raw2id[i] for i in adata.uns[\"top_non_zero_de_20\"][cond2name[query]]\n",
    "    ]\n",
    "    truth = adata[adata.obs.condition == query].X.toarray()[:, de_idx]\n",
    "    model = model.to('cuda')\n",
    "    print(device)\n",
    "    pred = model.pred_perturb_from_ctrl(adata_ctrl, query, gene_names, device, gene_ids, amp, pool_size).squeeze()[de_idx]\n",
    "    ctrl_means = adata[adata.obs[\"condition\"] == \"ctrl\"].to_df().mean()[de_idx].values\n",
    "\n",
    "    pred = pred - ctrl_means\n",
    "    truth = truth - ctrl_means\n",
    "\n",
    "    plt.figure(figsize=[16.5, 4.5])\n",
    "    plt.title(title + '\\n' + query)\n",
    "    plt.boxplot(truth, showfliers=False, medianprops=dict(linewidth=0))\n",
    "\n",
    "    for i in range(pred.shape[0]):\n",
    "        _ = plt.scatter(i + 1, pred[i], color=color, marker=marker)\n",
    "\n",
    "    plt.axhline(0, linestyle=\"dashed\", color=\"green\")\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_ticklabels(genes, rotation=90)\n",
    "\n",
    "    plt.ylabel(\"Change in Gene Expression over Control\", labelpad=10)\n",
    "    plt.tick_params(axis=\"x\", which=\"major\", pad=5)\n",
    "    plt.tick_params(axis=\"y\", which=\"major\", pad=5)\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we perform predictions, we can explore the test split of the Norman dataset in more detail. We are interested in this split, because this is data that the model has not seen during training. So performance on this split gives us a sense of model performance on unseen data. The `pert_data.subgroup` object contains information about the set of perturbations present in each of the train/val/test splits, and each can be explored in more detail. For example, the perturbation types in the test set are split into the following categories: \n",
    "- **unseen_single**: single gene perturbations that have not been seen during training\n",
    "- **combo_seen0**: two-gene perturbations, none of the genes has been seen perturbed (individually or as part of a combination) during training \n",
    "- **combo_seen1**: two-gene perturbations, one of the genes has been seen perturbed (individually or as part of a combination) during training\n",
    "- **combo_seen2**: two-gene perturbations, both genes has been seen perturbed (individually or as part of a combination) during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unseen_single: 37, combo_seen0: 9, combo_seen1: 52, combo_seen2: 18\n"
     ]
    }
   ],
   "source": [
    "pert_data.subgroup['test_subgroup'].keys()\n",
    "\n",
    "unseen_single = pert_data.subgroup['test_subgroup']['unseen_single']\n",
    "combo_seen0 = pert_data.subgroup['test_subgroup']['combo_seen0']\n",
    "combo_seen1 = pert_data.subgroup['test_subgroup']['combo_seen1']\n",
    "combo_seen2 = pert_data.subgroup['test_subgroup']['combo_seen2']\n",
    "\n",
    "print(f'unseen_single: {len(unseen_single)}, combo_seen0: {len(combo_seen0)}, combo_seen1: {len(combo_seen1)}, combo_seen2: {len(combo_seen2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of combinations of genes where none of the genes has been seen during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POU3F2+FOXL2',\n",
       " 'ZBTB10+PTPN12',\n",
       " 'CEBPB+PTPN12',\n",
       " 'CBL+PTPN12',\n",
       " 'RHOXF2BB+SET',\n",
       " 'CDKN1C+CDKN1B',\n",
       " 'CDKN1C+CDKN1A',\n",
       " 'CDKN1B+CDKN1A',\n",
       " 'C3orf72+FOXL2']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_seen0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='example_POU3F2+ctrl'></a>\n",
    "### Single-Gene Perturbation: Predicting perturbation response for perturbing the POU3F2 gene\n",
    "\n",
    "Then we can start exploring prediction on some of these perturbation categories. In the example below, we compare the perturbation prediction responses of scGPT and scGenePT_GO-C - scGPT + GO Cellular Components Annotations by perturbing the POU2F2 gene. Note that this gene has not been seen perturbed during training by the model. We do this by sampling n = 300 random controls from the training dataset and taking the mean of the average prediction for each control. According to NCBI Gene Card https://www.ncbi.nlm.nih.gov/gene/5454, overexpression of the protein encoded by POU3F2 is associated with an increase in the proliferation of melanoma cells. We can see that the genes FABP5, HSP90AB1, PRDX1, NPM1, TMSB10, PTMA are all better predicted as having a negative fold change over control by scGenePTGO−C, compared to scGPT which predicts a non-significant effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m models_to_predict \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscgpt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscgenept_go_c_gpt_concat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model, color, marker_type, title  \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(models_to_predict, colors, marker_types, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscGPT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscGenePT_GO-C\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mplot_perturbation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36mplot_perturbation\u001b[0;34m(model, query, model_type, color, marker, title, save_file, amp, pool_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n\u001b[0;32m---> 28\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_perturb_from_ctrl\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata_ctrl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgene_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgene_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()[de_idx]\n\u001b[1;32m     29\u001b[0m ctrl_means \u001b[38;5;241m=\u001b[39m adata[adata\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctrl\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_df()\u001b[38;5;241m.\u001b[39mmean()[de_idx]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     31\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred \u001b[38;5;241m-\u001b[39m ctrl_means\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/work/scGenePT_from_scratch/scGenePT/tutorials/../models/scGenePT.py:445\u001b[0m, in \u001b[0;36mscGenePT.pred_perturb_from_ctrl\u001b[0;34m(self, adata_ctrl, perturbation, gene_names, device, gene_ids, amp, pool_size, return_mean)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39mamp):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 445\u001b[0m         output_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgene_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mori_gene_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpert_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCLS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCCE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m            \u001b[49m\u001b[43mMVC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m            \u001b[49m\u001b[43mECS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m     pred_gene_values \u001b[38;5;241m=\u001b[39m output_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlm_output\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    457\u001b[0m     all_pred_gene_values\u001b[38;5;241m.\u001b[39mappend(pred_gene_values)\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/work/scGenePT_from_scratch/scGenePT/tutorials/../models/scGenePT.py:347\u001b[0m, in \u001b[0;36mscGenePT.forward\u001b[0;34m(self, src, values, input_pert_flags, src_key_padding_mask, CLS, CCE, MVC, ECS, do_sample)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m     processed_values \u001b[38;5;241m=\u001b[39m values\n\u001b[0;32m--> 347\u001b[0m transformer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_pert_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m output \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    351\u001b[0m device \u001b[38;5;241m=\u001b[39m src_key_padding_mask\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/work/scGenePT_from_scratch/scGenePT/tutorials/../models/scGenePT.py:269\u001b[0m, in \u001b[0;36mscGenePT._encode\u001b[0;34m(self, src, values, input_pert_flags, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    266\u001b[0m total_embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln\u001b[38;5;241m.\u001b[39mto(device)(total_embs)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Feed embeddings into transformer_encoder\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_embs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/transformer.py:387\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    384\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 387\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    390\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/transformer.py:707\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    705\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/opt/jupyter-envs/lang-generative-single-cell/aistrate-8gpu-3/conda/envs/scgenept2/lib/python3.10/site-packages/torch/nn/functional.py:5440\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5437\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5438\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5440\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5441\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5443\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pert = 'POU3F2+ctrl'\n",
    "colors = ['blue', 'fuchsia']\n",
    "marker_types = [ 'o','s']\n",
    "models_to_predict = ['scgpt', 'scgenept_go_c_gpt_concat']\n",
    "\n",
    "for model, color, marker_type, title  in zip(models_to_predict, colors, marker_types, ['scGPT', 'scGenePT_GO-C']):\n",
    "    plot_perturbation(trained_models[model], pert, model, color, marker_type, title, amp = True, pool_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the GO Gene Annotations that were used for this gene during training. If you don't already have the GO annotations downloaded, they can be retrieved from [here](https://drive.google.com/drive/folders/1NrRfw5-N0GAZSOQ5EBI5xRL7dj3doHZP?usp=drive_link) and should be placed under `models/gene_embeddings/gene_annotations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gene_annotations_dir = '../models/gene_embeddings/gene_annotations/'\n",
    "\n",
    "#GO-C Cellular Component Annotations\n",
    "GO_C_annotations_df = pd.read_csv(gene_annotations_dir + 'gene_ontology_C.csv')\n",
    "#GO-P Biological Process Annotations\n",
    "GO_P_annotations_df = pd.read_csv(gene_annotations_dir + 'gene_ontology_P.csv')\n",
    "#GO-F Molecular Function Annotations\n",
    "GO_F_annotations_df = pd.read_csv(gene_annotations_dir + 'gene_ontology_F.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can look at the GO-C Cellular Components annotations for the POU3F2 gene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_C_annotations_df[GO_C_annotations_df['gene'] == 'POU3F2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding the GO Cellular Component annotations, the model learns that this gene is localized mostly in: nucleoplasm, chromatin and transcription regulator complex. Localization of gene products in the cell plays an important role in their biological function, e.g. protein-protein interaction; regulation of gene expression, transportation of protein. This tells us that subcellular localization is helpful in being able to predict effects of perturbation of this gene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#example_CDKN1B+ctrl'></a>\n",
    "### Single-Gene Perturbation: Predicting perturbation response for perturbing the CDKN1B gene\n",
    "We can do this analysis for other genes as well. For example, the CDKN1B gene is another gene that has not been seen perturbed during training. According to this gene’s NCBI Gene Card https://www.ncbi.nlm.nih.gov/gene/1027, mutations in this gene are associated with multiple enodcrine neoplasia type IV. We can see that scGenePTGO−C predicts HSP90AA1, PTMA, RANBP1, CKS1B, PRDX1, PHF19 and NME1 as correctly down-regulated, as opposed to scGPT which predicts either neutral effect or positive fold change. Similarly, we speculate that the model learns to incorporate cellular location information to better predict gene expression change in response to genetic perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert = 'CDKN1B+ctrl'\n",
    "colors = ['blue', 'red']\n",
    "marker_types = [ 'o','s']\n",
    "models_to_predict = ['scgpt', 'scgenept_go_c_gpt_concat']\n",
    "\n",
    "for model, color, marker_type, title  in zip(models_to_predict, colors, marker_types, ['scGPT', 'scGenePT_GO-C']):\n",
    "    plot_perturbation(trained_models[model], pert, model, color, marker_type, title, amp = True, pool_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the subcellular localization annotations that the model sees during training for the CDK1NB gene are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO_C_annotations_df[GO_C_annotations_df['gene'] == 'CDKN1B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We speculate that having access to this information during training is helping the model make better predictions on the effect of perturbing this gene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#example_SAMD1+ZBTB1'></a>\n",
    "### Two-gene Perturbation: Predicting perturbation response for perturbing the gene combination FOXA1+FOXL2\n",
    "\n",
    "We can also look at effects of combination of genes. Below, we offer an example of predicting perturbation responses for the FOXA1+FOXL2 gene combination. <br>\n",
    "Note that you can experiment with different gene combinations in **combo_seen0, combo_seen1**, or **combo_seen2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert = 'FOXA1+FOXL2'\n",
    "colors = ['blue', 'green']\n",
    "marker_types = [ 'o', 's', 's']\n",
    "models_to_predict = ['scgpt', 'scgenept_ncbi+uniprot_gpt']\n",
    "\n",
    "for model, color, marker_type, title  in zip(models_to_predict, colors, marker_types, ['scGPT', 'scGenePT_NCBI+UniProt']):\n",
    "    plot_perturbation(trained_models[model], pert, model, color, marker_type, title, amp = True, pool_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can look at the NCBI and UniProt annotations for the genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCBI Gene Card Annotations\n",
    "NCBI_gene_card_summaries = json.load(open(gene_annotations_dir + 'NCBI_summary_of_genes.json', 'rb'))\n",
    "# NCBI Gene Card + UniProt protein summaries Annotations\n",
    "NCBI_UniProt_gene_card_protein_summaries = json.load(open(gene_annotations_dir + 'NCBI_UniProt_summary_of_genes.json', 'rb'))\n",
    "\n",
    "comb_genes = pert.split('+')\n",
    "for gene in comb_genes:\n",
    "    print(f\"Annotations for GENE: {gene}\")\n",
    "    print('='*30)\n",
    "    print(f\"NCBI Gene Card Summary: {NCBI_gene_card_summaries[gene]}\")\n",
    "    print('\\n')\n",
    "    print(f\"NCBI Gene Card + UniProt Protein Summary: {NCBI_UniProt_gene_card_protein_summaries[gene]}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predicting_on_rnd_ctrl'></a>\n",
    "## 3. Predicting on numpy arrays holding control samples\n",
    "\n",
    "We can make predictions on various data formats. Let's say we have a control sample held in a numpy array. We can use one of the trained models to make predictions. <br> \n",
    "For example, let's use the scGenePT-GO-C model trained on Norman. First, we need to load the trained model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'scgenept_go_c_gpt_concat'\n",
    "dataset_name = 'norman' \n",
    "pert_data = load_dataloader(dataset_name, batch_size = 64, val_batch_size = 64, split = 'simulation')\n",
    "\n",
    "model_filename = model_name2model_variation[model_name]\n",
    "model_location =  f'../models/finetuned/scgenept_go_c/{dataset_name}/{model_filename}'\n",
    "model, gene_ids =  load_trained_scgenept_model(pert_data, model_name, pretrained_scgpt_model_dir, model_location, device, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a control sample in a `NumPy array` and we want to predict the effect of perturbing the **FOSB** gene. Note that in the example below, the order of the genes in the ctrl_sample would have to match the one in gene_names of the dataset that the model was trained on. Otherwise, additional gene name matching should be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names = pert_data.gene_names.to_list()\n",
    "print(f'There are {len(gene_names)} genes, the first 10 are: {gene_names[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert = \"FOSB+ctrl\"\n",
    "ctrl_sample = np.random.rand(5045) # this can be replaced with a different control sample, as long as the order of the gene matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to assign the correct perturbation flags in the control sequence, so that the model knows what gene should get perturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pert_flags(ctrl_sample, gene_names, pert):\n",
    "    pert_flags = np.zeros(len(ctrl_sample))\n",
    "    if pert!= 'ctrl':\n",
    "        for x in pert.split('+'):\n",
    "            if x != 'ctrl':\n",
    "                pert_flags[gene_names.index(x)] = 1\n",
    "    pert_flags = torch.from_numpy(pert_flags).long().to(device).unsqueeze(0)\n",
    "    return pert_flags\n",
    "\n",
    "pert_flags = get_pert_flags(ctrl_sample, gene_names, pert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can get the model predictions by calling the model in inference mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_ctrl_sample(model, gene_ids, ctrl_sample, pert_flags, device):\n",
    "    ctrl_sample = torch.from_numpy(np.expand_dims(ctrl_sample, 0)).to(dtype = torch.float32).to(device)\n",
    "    gene_ids_tensor = torch.tensor(gene_ids).long().unsqueeze(0).to(device)\n",
    "    src_key_padding_mask = torch.zeros_like(gene_ids_tensor, dtype=torch.bool, device=device)\n",
    "    model = model.to(torch.float32)\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "        with torch.no_grad():\n",
    "            output_dict = model(\n",
    "                gene_ids_tensor,\n",
    "                ctrl_sample,\n",
    "                pert_flags,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                CLS=False,\n",
    "                CCE=False,\n",
    "                MVC=False,\n",
    "                ECS=False,\n",
    "                do_sample=True,\n",
    "            )\n",
    "    prediction = output_dict[\"mlm_output\"].float().detach().cpu().numpy()\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pred_ctrl_sample(model, gene_ids, ctrl_sample, pert_flags, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prediction_on_new_anndata_file'></a>\n",
    "## 4. Predicting on AnnData files\n",
    "We can follow a similar sequence to predict on an `AnnData` file. Note that in the example below, you can replace the `adata_ctrl` file with your file of choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_adata = pert_data.adata\n",
    "adata_ctrl = pert_adata[pert_adata.obs['condition'] == 'ctrl'][:100] # this can be any other AnnData file\n",
    "adata_ctrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the set and order of the genes in the AnnData file would have to match that of the genes the model has been trained on. In most cases, this will mean filtering the data to match this. The 5045 genes used by the model are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ctrl.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of them will correspond to values in the columns of `adata_ctrl.X`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ctrl.X # an entry (i, j) corresponds to the value of gene j in cell i; the 5045 genes must match to the list above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using similarly the model loaded above to generate predictions for perturbing a particular gene perturbation X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_pert = 'CEBPB+ctrl'\n",
    "\n",
    "ctrl_size = None # Note that if ctrl_size = None, all ctrl samples are used; if ctrl_size != None, then ctrl_size samples will get randomly sampled.\n",
    "return_mean = False # If this is True, then the mean of the predictions will get returned\n",
    "preds = model.pred_perturb_from_ctrl(adata_ctrl, gene_pert, gene_names, device, gene_ids, pool_size = ctrl_size, return_mean = False).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then assign the predictions to the anndata file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ctrl.layers[f'{model_name}_predictions'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ctrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a mean prediction over ctrl_size control samples, we can run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_size = 300\n",
    "preds_mean = model.pred_perturb_from_ctrl(adata_ctrl, gene_pert, gene_names, device, gene_ids, pool_size = ctrl_size, return_mean = True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWfXZ535yKi3"
   },
   "source": [
    "<a id='contact'></a>\n",
    "## Contact & Feedback\n",
    "\n",
    "Ana-Maria Istrate, aistrate@chanzuckerberg.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3jdy9WHyO8Z"
   },
   "source": [
    "## References\n",
    "\n",
    "1. Norman, Thomas M., et al. \"Exploring genetic interaction manifolds constructed from rich single-cell phenotypes.\" Science 365.6455 (2019): 786-793.\n",
    "2. Cui, Haotian, et al. \"scGPT: toward building a foundation model for single-cell multi-omics using generative AI.\" Nature Methods (2024): 1-11.\n",
    "3. Chen, Yiqun, and James Zou. \"GenePT: a simple but effective foundation model for genes and cells built from ChatGPT.\" bioRxiv (2024): 2023-10.\n",
    "4. Roohani, Yusuf, Kexin Huang, and Jure Leskovec. \"Predicting transcriptional outcomes of novel multigene perturbations with GEARS.\" Nature Biotechnology 42.6 (2024): 927-935."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "scgenept2",
   "language": "python",
   "name": "scgenept2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
